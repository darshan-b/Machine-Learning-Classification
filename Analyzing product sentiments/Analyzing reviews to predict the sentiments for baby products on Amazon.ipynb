{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "We will use a dataset consisting of baby product reviews on Amazon.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\Darshan\\AppData\\Local\\Temp\\graphlab_server_1486251939.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to darshanb@umd.edu and will expire on January 08, 2018.\n"
     ]
    }
   ],
   "source": [
    "products = graphlab.SFrame('amazon_baby.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see a preview of what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">review</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Planetwise Flannel Wipes</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">These flannel wipes are<br>OK, but in my opinion ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Planetwise Wipe Pouch</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">it came early and was not<br>disappointed. i love ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Annas Dream Full Quilt<br>with 2 Shams ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Very soft and comfortable<br>and warmer than it ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[3 rows x 3 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tname\tstr\n",
       "\treview\tstr\n",
       "\trating\tfloat\n",
       "\n",
       "Rows: 3\n",
       "\n",
       "Data:\n",
       "+-------------------------------+-------------------------------+--------+\n",
       "|              name             |             review            | rating |\n",
       "+-------------------------------+-------------------------------+--------+\n",
       "|    Planetwise Flannel Wipes   | These flannel wipes are OK... |  3.0   |\n",
       "|     Planetwise Wipe Pouch     | it came early and was not ... |  5.0   |\n",
       "| Annas Dream Full Quilt wit... | Very soft and comfortable ... |  5.0   |\n",
       "+-------------------------------+-------------------------------+--------+\n",
       "[3 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore a specific example of a baby product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A fucntion to remove punctuations from the reviews\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(None, string.punctuation) \n",
    "\n",
    "#Applying it to all the reviews in the dataset\n",
    "review_without_punctuation = products['review'].apply(remove_punctuation)\n",
    "\n",
    "#Tokenizing the review\n",
    "products['word_count'] = graphlab.text_analytics.count_words(review_without_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in the **word_count** column is a dictionary where the key is the word and the value is a count of the number of times the word occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract sentiments\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products = products[products['rating'] != 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, test_data = products.random_split(.8, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data. This model will use the column **word_count** as a feature and the column **sentiment** as the target. We will use `validation_set=None` to obtain same results as everyone else. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_model = graphlab.logistic_classifier.create(train_data,\n",
    "                                                      target = 'sentiment',\n",
    "                                                      features=['word_count'],\n",
    "                                                      validation_set=None,verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fitted the model, we can extract the weights (coefficients) as an SFrame as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = sentiment_model.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of `121713` coefficients in the model. Recall from the lecture that positive weights $w_j$ correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. \n",
    "\n",
    "Fill in the following block of code to calculate how many *weights* are positive ( >= 0). (**Hint**: The `'value'` column in SFrame *weights* must be positive ( >= 0))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive weights: 68419 \n",
      "Number of negative weights: 53294 \n"
     ]
    }
   ],
   "source": [
    "num_positive_weights = len(weights[weights['value']>=0])\n",
    "num_negative_weights = len(weights)-num_positive_weights\n",
    "print \"Number of positive weights: %s \" % num_positive_weights\n",
    "print \"Number of negative weights: %s \" % num_negative_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with logistic regression\n",
    "\n",
    "Now that a model is trained, we can make predictions on the **test data**. In this section, we will explore this in the context of 3 examples in the test dataset.  We refer to this set of 3 examples as the **sample_test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 2.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "sample_test_data = test_data[10:13]\n",
    "print sample_test_data['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig deeper into the first row of the **sample_test_data**. Here's the full review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data[0]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That review seems pretty positive.\n",
    "\n",
    "Now, let's see what the next row of the **sample_test_data** looks like. As we could guess from the sentiment (-1), the review is quite negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data[1]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a **class** prediction for the **sample_test_data**. The `sentiment_model` should predict **+1** if the sentiment is positive and **-1** if the sentiment is negative. Recall from the lecture that the **score** (sometimes called **margin**) for the logistic regression model  is defined as:\n",
    "\n",
    "$$\n",
    "\\mbox{score}_i = \\mathbf{w}^T h(\\mathbf{x}_i)\n",
    "$$ \n",
    "\n",
    "where $h(\\mathbf{x}_i)$ represents the features for example $i$.  We will write some code to obtain the **scores** using GraphLab Create. For each row, the **score** (or margin) is a number in the range **[-inf, inf]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.734619727058961, -5.73413099676015, -14.668460404468345]\n"
     ]
    }
   ],
   "source": [
    "scores = sentiment_model.predict(sample_test_data, output_type='margin')\n",
    "print scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment\n",
    "\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w}^T h(\\mathbf{x}_i) > 0 \\\\\n",
    "      -1 & \\mathbf{w}^T h(\\mathbf{x}_i) \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Using scores, write code to calculate $\\hat{y}$, the class predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions according to GraphLab Create:\n",
      "[1L, -1L, -1L]\n"
     ]
    }
   ],
   "source": [
    "print \"Class predictions according to GraphLab Create:\" \n",
    "y=scores.apply(lambda x: +1 if x>0 else -1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability predictions\n",
    "\n",
    " calculate the probability predictions from the scores using:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))}.\n",
    "$$\n",
    "\n",
    "Using the variable **scores** calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range **[0, 1]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.98812385e-01   3.22326818e-03   4.26155800e-07]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "prob_prediction=1/(1+np.exp(-scores))\n",
    "print(prob_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions according to GraphLab Create:\n",
      "[0.9988123848377194, 0.003223268181801026, 4.2615579966561597e-07]\n"
     ]
    }
   ],
   "source": [
    "print \"Class predictions according to GraphLab Create:\" \n",
    "print sentiment_model.predict(sample_test_data, output_type='probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most positive (and negative) review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to examining the full test dataset, **test_data**, and use GraphLab Create to form predictions on all of the test data points for faster performance.\n",
    "\n",
    "Using the `sentiment_model`, find the 20 reviews in the entire **test_data** with the **highest probability** of being classified as a **positive review**. We refer to these as the \"most positive reviews.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1469\n",
      "Fisher-Price Royal Potty\n",
      "Fisher-Price Royal Potty\n",
      "Fisher-Price Ocean Wonders Aquarium Bouncer\n",
      "Evenflo Take Me Too Premiere Tandem Stroller - Castlebay\n",
      "Chicco Cortina KeyFit 30 Travel System in Adventure\n",
      "Adiri BPA Free Natural Nurser Ultimate Bottle Stage 1 White, Slow Flow (0-3 months)\n",
      "Safety 1st High-Def Digital Monitor\n",
      "The First Years 3 Pack Breastflow Bottle, 9 Ounce\n",
      "Prince Lionheart Warmies Wipes Warmer\n",
      "Safety 1st Lift Lock and Swing Gate\n",
      "Peg-Perego Tatamia High Chair, White Latte\n",
      "Safety 1st Exchangeable Tip 3 in 1 Thermometer\n",
      "Cloth Diaper Sprayer--styles may vary\n",
      "Nuby Natural Touch Silicone Travel Infa Feeder, Colors May Vary, 3 Ounce\n",
      "Snuza Portable Baby Movement Monitor\n",
      "The First Years True Choice P400 Premium Digital Monitor, 2 Parent Unit\n",
      "Valco Baby Tri-mode Twin Stroller EX- Hot Chocolate\n",
      "Levana Safe N'See Digital Video Baby Monitor with Talk-to-Baby Intercom and Lullaby Control (LV-TW501)\n",
      "Jolly Jumper Arctic Sneak A Peek Infant Car Seat Cover Black\n",
      "Munchkin Nursery Projector and Sound System, White\n",
      "VTech Communications Safe &amp; Sounds Full Color Video and Audio Monitor\n",
      "Negative\n",
      "Jolly Jumper Arctic Sneak A Peek Infant Car Seat Cover Black\n",
      "Levana Safe N'See Digital Video Baby Monitor with Talk-to-Baby Intercom and Lullaby Control (LV-TW501)\n",
      "Snuza Portable Baby Movement Monitor\n",
      "Fisher-Price Ocean Wonders Aquarium Bouncer\n",
      "VTech Communications Safe &amp; Sounds Full Color Video and Audio Monitor\n",
      "Safety 1st High-Def Digital Monitor\n",
      "Chicco Cortina KeyFit 30 Travel System in Adventure\n",
      "Prince Lionheart Warmies Wipes Warmer\n",
      "Valco Baby Tri-mode Twin Stroller EX- Hot Chocolate\n",
      "Adiri BPA Free Natural Nurser Ultimate Bottle Stage 1 White, Slow Flow (0-3 months)\n",
      "Munchkin Nursery Projector and Sound System, White\n",
      "The First Years True Choice P400 Premium Digital Monitor, 2 Parent Unit\n",
      "Nuby Natural Touch Silicone Travel Infa Feeder, Colors May Vary, 3 Ounce\n",
      "Peg-Perego Tatamia High Chair, White Latte\n",
      "Fisher-Price Royal Potty\n",
      "Safety 1st Exchangeable Tip 3 in 1 Thermometer\n",
      "Safety 1st Lift Lock and Swing Gate\n",
      "Evenflo Take Me Too Premiere Tandem Stroller - Castlebay\n",
      "Cloth Diaper Sprayer--styles may vary\n",
      "The First Years 3 Pack Breastflow Bottle, 9 Ounce\n"
     ]
    }
   ],
   "source": [
    "test_prob=sentiment_model.predict(test_data,output_type='probability')\n",
    "t=test_prob.topk_index(20,reverse=True)\n",
    "tf=graphlab.SFrame(t)\n",
    "tf['index']=np.arange(0,len(tf))\n",
    "\n",
    "ind=(tf[tf['X1']>0])\n",
    "ind1=ind['index'][:]\n",
    "\n",
    "print(ind1[0])\n",
    "find=ind1.astype(int)\n",
    "print(test_data['name'][find[0]])\n",
    "\n",
    "for i in range(len(ind1)):\n",
    "    print(test_data['name'][find[i]])\n",
    "\n",
    "print('Negative')\n",
    "#negative\n",
    "d=graphlab.SFrame(test_prob)\n",
    "d['index']=np.arange(0,len(test_prob))\n",
    "sort_d=d.sort('X1',ascending=True)[0:20]\n",
    "# print(sort_d)\n",
    "find_negative=sort_d['index'].astype(int)\n",
    "for i in range(len(ind1)):\n",
    "    print(test_data['name'][find_negative[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "KidCo Magnet Lock Starter Set\n",
      "Fisher-Price Rainforest Melodies and Lights Deluxe Gym\n",
      "Baby Jogger City Mini GT Single Stroller, Shadow/Orange\n",
      "Eddie Bauer Trailmaker Travel System - Sinclair\n",
      "Baby Jogger City Mini GT Double Stroller, Shadow/Orange\n",
      "Fisher-Price Grow with Me High Chair, Bunny\n",
      "Maxi-Cosi Pria 70 with Tiny Fit Convertible Car Seat\n",
      "Orbit Baby Stroller Travel System G2, Mocha\n",
      "Regalo Easy Step Walk Thru Gate, White\n",
      "Baby BeeHinds Magic Alls Minkee All In One Pocket Diaper Snaps - Marine Green Small\n",
      "Graco SnugRide Click Connect 35 - Lyric\n",
      "Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatware, Bowl, Plate, Tumbler Set, Colorful\n",
      "Barin Toys Teething Pendant, Tiny Bird\n",
      "Cozy Infant Remote Wireless Video Baby Monitor with 3.5-Inch Color LCD Screen, Infrared Optic Night Vision and Remote Camera Pan, Tilt and Zoom, 3.5 Inch\n",
      "Safety 1st Tot-Lok Four Lock Assembly\n",
      "Summer Infant Complete Nursery Care Kit\n",
      "Gerber First Essential Clear View BPA Free Plastic Nurser With Latex Nipple, Assorted Colors, 9 Ounce, 3 Pack\n",
      "North States Supergate Extra Tall Easy Close Gate, Bronze\n",
      "Annabel Karmel Lunch Box\n",
      "We Sell Mats 36 Sq Ft Alphabet and Number Floor Mat\n"
     ]
    }
   ],
   "source": [
    "print('Positive')\n",
    "#negative\n",
    "d3=graphlab.SFrame(test_prob)\n",
    "d3['index']=np.arange(0,len(test_prob))\n",
    "sort_p=d3.sort('X1',ascending=False)\n",
    "sort_p=sort_p[0:20]\n",
    "# print(sort_d)\n",
    "find_p=sort_p['index'].astype(int)\n",
    "for i in range(len(find_p)):\n",
    "    print(test_data['name'][find_p[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifier.Accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    # First get the predictions\n",
    "    pred=model.predict(data)\n",
    "    # Compute the number of correctly classified examples\n",
    "    right_count=0\n",
    "    for i in range(len(pred)):\n",
    "        if(pred[i]==true_labels[i]):\n",
    "            right_count+=1\n",
    "    # Then compute accuracy by dividing num_correct by total number of examples\n",
    "    accuracy=right_count/float(len(data))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the classification accuracy of the **sentiment_model** on the **test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the sentiment model is: 0.9145\n"
     ]
    }
   ],
   "source": [
    "print \"The accuracy of the sentiment model is:\",'%.4f' %get_classification_accuracy(sentiment_model, test_data, test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn another classifier with fewer words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove count for all the words not in the dictionary for significant words\n",
    "train_data['word_count_subset'] = train_data['word_count'].dict_trim_by_keys(significant_words, exclude=False)\n",
    "test_data['word_count_subset'] = test_data['word_count'].dict_trim_by_keys(significant_words, exclude=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it came early and was not disappointed. i love planet wise bags and now my wipe holder. it keps my osocozy wipes moist and does not leak. highly recommend it.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['review'] # WHat does the data look like now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **word_count** column had been working with before looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 3L, 'love': 1L, 'it': 3L, 'highly': 1L, 'osocozy': 1L, 'bags': 1L, 'leak': 1L, 'moist': 1L, 'does': 1L, 'recommend': 1L, 'was': 1L, 'wipes': 1L, 'disappointed': 1L, 'early': 1L, 'not': 2L, 'now': 1L, 'holder': 1L, 'wipe': 1L, 'keps': 1L, 'wise': 1L, 'i': 1L, 'planet': 1L, 'my': 2L, 'came': 1L}\n"
     ]
    }
   ],
   "source": [
    "print train_data[0]['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only working with a subset of these words, the column **word_count_subset** is a subset of the above dictionary. In this example, only 2 `significant words` are present in this review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love': 1L, 'disappointed': 1L}\n"
     ]
    }
   ],
   "source": [
    "print train_data[0]['word_count_subset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic regression model on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build a classifier with **word_count_subset** as the feature and **sentiment** as the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 133416</pre>"
      ],
      "text/plain": [
       "Number of examples          : 133416"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 1</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 20</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 21</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting Newton Method</pre>"
      ],
      "text/plain": [
       "Starting Newton Method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Elapsed Time | Training-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Elapsed Time | Training-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 2        | 0.227944     | 0.862917          |</pre>"
      ],
      "text/plain": [
       "| 1         | 2        | 0.227944     | 0.862917          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3        | 0.362803     | 0.865713          |</pre>"
      ],
      "text/plain": [
       "| 2         | 3        | 0.362803     | 0.865713          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 4        | 0.474099     | 0.866478          |</pre>"
      ],
      "text/plain": [
       "| 3         | 4        | 0.474099     | 0.866478          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 5        | 0.587902     | 0.866748          |</pre>"
      ],
      "text/plain": [
       "| 4         | 5        | 0.587902     | 0.866748          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 6        | 0.702205     | 0.866815          |</pre>"
      ],
      "text/plain": [
       "| 5         | 6        | 0.702205     | 0.866815          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 7        | 0.809491     | 0.866815          |</pre>"
      ],
      "text/plain": [
       "| 6         | 7        | 0.809491     | 0.866815          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Class                          : LogisticClassifier\n",
       "\n",
       "Schema\n",
       "------\n",
       "Number of coefficients         : 21\n",
       "Number of examples             : 133416\n",
       "Number of classes              : 2\n",
       "Number of feature columns      : 1\n",
       "Number of unpacked features    : 20\n",
       "\n",
       "Hyperparameters\n",
       "---------------\n",
       "L1 penalty                     : 0.0\n",
       "L2 penalty                     : 0.01\n",
       "\n",
       "Training Summary\n",
       "----------------\n",
       "Solver                         : newton\n",
       "Solver iterations              : 6\n",
       "Solver status                  : SUCCESS: Optimal solution found.\n",
       "Training time (sec)            : 0.8371\n",
       "\n",
       "Settings\n",
       "--------\n",
       "Log-likelihood                 : 44323.7254\n",
       "\n",
       "Highest Positive Coefficients\n",
       "-----------------------------\n",
       "word_count_subset[loves]       : 1.6773\n",
       "word_count_subset[perfect]     : 1.5145\n",
       "word_count_subset[love]        : 1.3654\n",
       "(intercept)                    : 1.2995\n",
       "word_count_subset[easy]        : 1.1937\n",
       "\n",
       "Lowest Negative Coefficients\n",
       "----------------------------\n",
       "word_count_subset[disappointed] : -2.3551\n",
       "word_count_subset[return]      : -2.1173\n",
       "word_count_subset[waste]       : -2.0428\n",
       "word_count_subset[broke]       : -1.658\n",
       "word_count_subset[money]       : -0.8979"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model = graphlab.logistic_classifier.create(train_data,\n",
    "                                                   target = 'sentiment',\n",
    "                                                   features=['word_count_subset'],\n",
    "                                                   validation_set=None)\n",
    "simple_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the classification accuracy using the `get_classification_accuracy` function you implemented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the selected words model is: 0.869300455964\n"
     ]
    }
   ],
   "source": [
    "print\"The accuracy of the selected words model is:\",get_classification_accuracy(simple_model, test_data, test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will inspect the weights (coefficients) of the **simple_model**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">index</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">class</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">value</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">stderr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">(intercept)</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.2995449552</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0120888541331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">word_count_subset</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">disappointed</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-2.35509250061</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0504149888557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">word_count_subset</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">love</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.36543549368</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0303546295109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">word_count_subset</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">well</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.504256746398</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.021381300631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">word_count_subset</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">product</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.320555492996</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0154311321362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">word_count_subset</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">loves</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.67727145556</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0482328275384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">word_count_subset</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">little</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.520628636025</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0214691475665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">word_count_subset</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">work</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.621700012425</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0230330597946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">word_count_subset</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">easy</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.19366189833</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.029288869202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">word_count_subset</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">great</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.94469126948</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0209509926591</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[21 rows x 5 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tname\tstr\n",
       "\tindex\tstr\n",
       "\tclass\tint\n",
       "\tvalue\tfloat\n",
       "\tstderr\tfloat\n",
       "\n",
       "Rows: 21\n",
       "\n",
       "Data:\n",
       "+-------------------+--------------+-------+-----------------+-----------------+\n",
       "|        name       |    index     | class |      value      |      stderr     |\n",
       "+-------------------+--------------+-------+-----------------+-----------------+\n",
       "|    (intercept)    |     None     |   1   |   1.2995449552  | 0.0120888541331 |\n",
       "| word_count_subset | disappointed |   1   |  -2.35509250061 | 0.0504149888557 |\n",
       "| word_count_subset |     love     |   1   |  1.36543549368  | 0.0303546295109 |\n",
       "| word_count_subset |     well     |   1   |  0.504256746398 |  0.021381300631 |\n",
       "| word_count_subset |   product    |   1   | -0.320555492996 | 0.0154311321362 |\n",
       "| word_count_subset |    loves     |   1   |  1.67727145556  | 0.0482328275384 |\n",
       "| word_count_subset |    little    |   1   |  0.520628636025 | 0.0214691475665 |\n",
       "| word_count_subset |     work     |   1   | -0.621700012425 | 0.0230330597946 |\n",
       "| word_count_subset |     easy     |   1   |  1.19366189833  |  0.029288869202 |\n",
       "| word_count_subset |    great     |   1   |  0.94469126948  | 0.0209509926591 |\n",
       "+-------------------+--------------+-------+-----------------+-----------------+\n",
       "[21 rows x 5 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the coefficients (in descending order) by the **value** to obtain the coefficients with the most positive effect on the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-------+-----------------+-----------------+\n",
      "|        name       |    index     | class |      value      |      stderr     |\n",
      "+-------------------+--------------+-------+-----------------+-----------------+\n",
      "| word_count_subset |    loves     |   1   |  1.67727145556  | 0.0482328275384 |\n",
      "| word_count_subset |   perfect    |   1   |  1.51448626703  |  0.049861952294 |\n",
      "| word_count_subset |     love     |   1   |  1.36543549368  | 0.0303546295109 |\n",
      "|    (intercept)    |     None     |   1   |   1.2995449552  | 0.0120888541331 |\n",
      "| word_count_subset |     easy     |   1   |  1.19366189833  |  0.029288869202 |\n",
      "| word_count_subset |    great     |   1   |  0.94469126948  | 0.0209509926591 |\n",
      "| word_count_subset |    little    |   1   |  0.520628636025 | 0.0214691475665 |\n",
      "| word_count_subset |     well     |   1   |  0.504256746398 |  0.021381300631 |\n",
      "| word_count_subset |     able     |   1   |  0.191438302295 | 0.0337581955697 |\n",
      "| word_count_subset |     old      |   1   | 0.0853961886678 | 0.0200863423025 |\n",
      "| word_count_subset |     car      |   1   |  0.058834990068 | 0.0168291532091 |\n",
      "| word_count_subset |     less     |   1   | -0.209709815216 |  0.040505735954 |\n",
      "| word_count_subset |   product    |   1   | -0.320555492996 | 0.0154311321362 |\n",
      "| word_count_subset |    would     |   1   | -0.362308947711 | 0.0127544751985 |\n",
      "| word_count_subset |     even     |   1   |  -0.51173855127 | 0.0199612760261 |\n",
      "| word_count_subset |     work     |   1   | -0.621700012425 | 0.0230330597946 |\n",
      "| word_count_subset |    money     |   1   | -0.897884155776 | 0.0339936732836 |\n",
      "| word_count_subset |    broke     |   1   |  -1.65796447838 | 0.0580878907166 |\n",
      "| word_count_subset |    waste     |   1   |   -2.042773611  | 0.0644702932444 |\n",
      "| word_count_subset |    return    |   1   |  -2.11729659718 | 0.0578650807241 |\n",
      "| word_count_subset | disappointed |   1   |  -2.35509250061 | 0.0504149888557 |\n",
      "+-------------------+--------------+-------+-----------------+-----------------+\n",
      "[21 rows x 5 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_model.coefficients.sort('value', ascending=False).print_rows(num_rows=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many words have a positive coefficient\n",
    "d=simple_model.coefficients.sort('value', ascending=False)\n",
    "coef=d[d['name']!='(intercept)']\n",
    "d=coef['index'][coef['value']>=0]\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compare the accuracy of the **sentiment_model** and the **simple_model** using the `get_classification_accuracy` method you implemented above.\n",
    "\n",
    "First, compute the classification accuracy of the **sentiment_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Sentiment model i.e. all words on training data is: 0.979440247047\n",
      "The accuracy of Selected words model i.e. all words on training data is: 0.866815074654\n",
      "The accuracy of Sentiment model i.e. all words on test data is: 0.914536837053\n",
      "The accuracy of Selected words model i.e. all words on test data is: 0.869300455964\n"
     ]
    }
   ],
   "source": [
    "print \"The accuracy of Sentiment model i.e. all words on training data is:\",get_classification_accuracy(sentiment_model,train_data,train_data['sentiment'])\n",
    "print \"The accuracy of Selected words model i.e. all words on training data is:\",get_classification_accuracy(simple_model,train_data,train_data['sentiment'])\n",
    "print \"The accuracy of Sentiment model i.e. all words on test data is:\" ,get_classification_accuracy(sentiment_model,test_data,test_data['sentiment'])\n",
    "print \"The accuracy of Selected words model i.e. all words on test data is:\",get_classification_accuracy(simple_model,test_data,test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points. At the very least, you should healthily beat the majority class classifier, otherwise, the model is (usually) pointless.\n",
    "\n",
    "What is the majority class in the **train_data**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurac of a majoirty class classifier will be: 0.842782577394\n"
     ]
    }
   ],
   "source": [
    "num_positive  = (test_data['sentiment'] == +1).sum()\n",
    "num_negative = (test_data['sentiment'] == -1).sum()\n",
    "print \"The accurac of a majoirty class classifier will be:\",num_positive/float(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
